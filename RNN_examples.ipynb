{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNNs Pytorch Examples\n",
    "\n",
    "This notebook contains examples using some RNNs implementations available in Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  LSTMCell vs LSTM (GPU Support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " step 0 , Input : torch.Size([3, 10])\n",
      " step 0 , hidden state : torch.Size([3, 20])\n",
      " step 0 , cell state : torch.Size([3, 20])\n",
      " step 1 , Input : torch.Size([3, 10])\n",
      " step 1 , hidden state : torch.Size([3, 20])\n",
      " step 1 , cell state : torch.Size([3, 20])\n",
      " \n",
      " Output LSTMCell: torch.Size([2, 3, 20])\n",
      " \n",
      " Output LSTMCell:\n",
      " tensor([[[ 0.2552, -0.1090, -0.0835,  0.2958, -0.4213, -0.0170,  0.2474,\n",
      "           0.1677, -0.3955, -0.1091,  0.2386, -0.0052,  0.3028,  0.2637,\n",
      "           0.0113, -0.3665, -0.0687, -0.0280, -0.3560,  0.0247],\n",
      "         [-0.0958, -0.0987,  0.3122, -0.1819, -0.0390, -0.3634,  0.1293,\n",
      "           0.2141, -0.5724, -0.1846, -0.3133, -0.1564, -0.0349,  0.2602,\n",
      "           0.3982, -0.3867,  0.3485,  0.0338, -0.2344,  0.0718],\n",
      "         [-0.1596,  0.0429,  0.3663, -0.0377,  0.1968, -0.2228, -0.0025,\n",
      "          -0.0077, -0.1359,  0.0810,  0.1197, -0.0336,  0.0129, -0.1988,\n",
      "          -0.2814,  0.2207, -0.0302, -0.1498, -0.3188, -0.0169]],\n",
      "\n",
      "        [[ 0.1216, -0.0640, -0.1142, -0.1368, -0.2694, -0.1684,  0.1206,\n",
      "           0.1096, -0.2894, -0.0532,  0.1241,  0.0037,  0.0609,  0.0435,\n",
      "          -0.0029,  0.0019, -0.0049, -0.0011, -0.2284, -0.0170],\n",
      "         [-0.1441,  0.0221,  0.1218, -0.1164,  0.0715, -0.1197,  0.0551,\n",
      "           0.0997, -0.3187, -0.0236, -0.1777, -0.2872, -0.1065,  0.4108,\n",
      "           0.1640, -0.2467,  0.3084, -0.0291, -0.2907,  0.0078],\n",
      "         [-0.2493, -0.0424,  0.1005,  0.0169,  0.2249, -0.1074,  0.0999,\n",
      "          -0.0094, -0.1216, -0.0834,  0.0590, -0.0979,  0.0496, -0.1381,\n",
      "          -0.3088, -0.0315,  0.0167, -0.2628, -0.1535,  0.0806]]],\n",
      "       grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(12)\n",
    "\n",
    "# features 10, hidden size 20\n",
    "rnn = nn.LSTMCell(10, 20)\n",
    "# (time_steps, batch, input_size)\n",
    "input = torch.randn(2, 3, 10)\n",
    "# (batch, hidden_size)\n",
    "hx = torch.randn(3, 20)\n",
    "# (batch, hidden_size)\n",
    "cx = torch.randn(3, 20)\n",
    "# list to save outputs each time step\n",
    "output = []\n",
    "for i in range(input.size()[0]):\n",
    "        print(f\" step {i} , Input : {input[i].shape}\")\n",
    "        print(f\" step {i} , hidden state : {hx.shape}\")\n",
    "        print(f\" step {i} , cell state : {cx.shape}\")\n",
    "\n",
    "        hx, cx = rnn(input[i], (hx, cx))\n",
    "        output.append(hx)       \n",
    "\n",
    "output  = torch.stack(output, dim = 0)\n",
    "\n",
    "print(f\" \\n Output LSTMCell: {output.shape}\")\n",
    "print(f\" \\n Output LSTMCell:\\n {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Output : torch.Size([2, 3, 20])\n",
      " \n",
      " hidden state : torch.Size([1, 3, 20])\n",
      " \n",
      " cell state : torch.Size([1, 3, 20])\n",
      " \n",
      " Output LSTM:\n",
      " tensor([[[ 0.2552, -0.1090, -0.0835,  0.2958, -0.4213, -0.0170,  0.2474,\n",
      "           0.1677, -0.3955, -0.1091,  0.2386, -0.0052,  0.3028,  0.2637,\n",
      "           0.0113, -0.3665, -0.0687, -0.0280, -0.3560,  0.0247],\n",
      "         [-0.0958, -0.0987,  0.3122, -0.1819, -0.0390, -0.3634,  0.1293,\n",
      "           0.2141, -0.5724, -0.1846, -0.3133, -0.1564, -0.0349,  0.2602,\n",
      "           0.3982, -0.3867,  0.3485,  0.0338, -0.2344,  0.0718],\n",
      "         [-0.1596,  0.0429,  0.3663, -0.0377,  0.1968, -0.2228, -0.0025,\n",
      "          -0.0077, -0.1359,  0.0810,  0.1197, -0.0336,  0.0129, -0.1988,\n",
      "          -0.2814,  0.2207, -0.0302, -0.1498, -0.3188, -0.0169]],\n",
      "\n",
      "        [[ 0.1216, -0.0640, -0.1142, -0.1368, -0.2694, -0.1684,  0.1206,\n",
      "           0.1096, -0.2894, -0.0532,  0.1241,  0.0037,  0.0609,  0.0435,\n",
      "          -0.0029,  0.0019, -0.0049, -0.0011, -0.2284, -0.0170],\n",
      "         [-0.1441,  0.0221,  0.1218, -0.1164,  0.0715, -0.1197,  0.0551,\n",
      "           0.0997, -0.3187, -0.0236, -0.1777, -0.2872, -0.1065,  0.4108,\n",
      "           0.1640, -0.2467,  0.3084, -0.0291, -0.2907,  0.0078],\n",
      "         [-0.2493, -0.0424,  0.1005,  0.0169,  0.2249, -0.1074,  0.0999,\n",
      "          -0.0094, -0.1216, -0.0834,  0.0590, -0.0979,  0.0496, -0.1381,\n",
      "          -0.3088, -0.0315,  0.0167, -0.2628, -0.1535,  0.0806]]],\n",
      "       grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(12)\n",
    "\n",
    "# (input_size, hidden_size, layers)\n",
    "rnn = nn.LSTM(10, 20, 1)\n",
    "# (seq_len, batch, input_size)\n",
    "input = torch.randn(2, 3, 10)\n",
    "# (num_layers, batch, hidden_size)\n",
    "h0 = torch.randn(1, 3, 20)\n",
    "c0 = torch.randn(1, 3, 20)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))\n",
    "\n",
    "print(f\" \\n Output : {output.shape}\")\n",
    "print(f\" \\n hidden state : {hn.shape}\")\n",
    "print(f\" \\n cell state : {cn.shape}\")\n",
    "print(f\" \\n Output LSTM:\\n {output}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using LSTM like an LSTMCell (loop through time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " step 0 , Input : torch.Size([1, 3, 10])\n",
      " step 0 , hidden state : torch.Size([1, 3, 20])\n",
      " step 0 , cell state : torch.Size([1, 3, 20])\n",
      " \n",
      " step 1 , Input : torch.Size([1, 3, 10])\n",
      " step 1 , hidden state : torch.Size([1, 3, 20])\n",
      " step 1 , cell state : torch.Size([1, 3, 20])\n",
      " \n",
      " Output LSTM: \n",
      " tensor([[[[ 0.2552, -0.1090, -0.0835,  0.2958, -0.4213, -0.0170,  0.2474,\n",
      "            0.1677, -0.3955, -0.1091,  0.2386, -0.0052,  0.3028,  0.2637,\n",
      "            0.0113, -0.3665, -0.0687, -0.0280, -0.3560,  0.0247],\n",
      "          [-0.0958, -0.0987,  0.3122, -0.1819, -0.0390, -0.3634,  0.1293,\n",
      "            0.2141, -0.5724, -0.1846, -0.3133, -0.1564, -0.0349,  0.2602,\n",
      "            0.3982, -0.3867,  0.3485,  0.0338, -0.2344,  0.0718],\n",
      "          [-0.1596,  0.0429,  0.3663, -0.0377,  0.1968, -0.2228, -0.0025,\n",
      "           -0.0077, -0.1359,  0.0810,  0.1197, -0.0336,  0.0129, -0.1988,\n",
      "           -0.2814,  0.2207, -0.0302, -0.1498, -0.3188, -0.0169]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1216, -0.0640, -0.1142, -0.1368, -0.2694, -0.1684,  0.1206,\n",
      "            0.1096, -0.2894, -0.0532,  0.1241,  0.0037,  0.0609,  0.0435,\n",
      "           -0.0029,  0.0019, -0.0049, -0.0011, -0.2284, -0.0170],\n",
      "          [-0.1441,  0.0221,  0.1218, -0.1164,  0.0715, -0.1197,  0.0551,\n",
      "            0.0997, -0.3187, -0.0236, -0.1777, -0.2872, -0.1065,  0.4108,\n",
      "            0.1640, -0.2467,  0.3084, -0.0291, -0.2907,  0.0078],\n",
      "          [-0.2493, -0.0424,  0.1005,  0.0169,  0.2249, -0.1074,  0.0999,\n",
      "           -0.0094, -0.1216, -0.0834,  0.0590, -0.0979,  0.0496, -0.1381,\n",
      "           -0.3088, -0.0315,  0.0167, -0.2628, -0.1535,  0.0806]]]],\n",
      "       grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(12)\n",
    "\n",
    "# (input_size, hidden_size, layers)\n",
    "rnn = nn.LSTM(10, 20, 1)\n",
    "# (seq_len, batch, input_size)\n",
    "input = torch.randn(2, 3, 10)\n",
    "# (num_layers, batch, hidden_size)\n",
    "hx = torch.randn(1, 3, 20)\n",
    "cx = torch.randn(1, 3, 20)\n",
    "\n",
    "outputs = []\n",
    "for i in range(input.shape[0]):\n",
    "    \n",
    "        print(f\" \\n step {i} , Input : {input[i:i+1,:,:].shape}\")\n",
    "        print(f\" step {i} , hidden state : {hx.shape}\")\n",
    "        print(f\" step {i} , cell state : {cx.shape}\")\n",
    "\n",
    "        output, (hx, cx) = rnn(input[i:i+1,:,:], (hx, cx))\n",
    "        outputs.append(output)\n",
    "        \n",
    "outputs  = torch.stack(outputs, dim = 0)\n",
    "print(f\" \\n Output LSTM: \\n {outputs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using GRUCell vs GRU for one2many/vec2seq architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "\n",
    "# (features=4, hiddenlayer1=20)\n",
    "rnn1 = nn.GRUCell(4, 20)\n",
    "# (hiddenlayer1=20, hiddenlayer2=20)\n",
    "rnn2 = nn.GRUCell(20, 20)\n",
    "# (hiddenlayer2=20, output=20)\n",
    "linear = nn.Linear(20,4)\n",
    "# 2 batches, 4 features (input_v: \"first input, 1 time step\")\n",
    "input_v = torch.randn(2, 4)\n",
    "# batch, hidden size\n",
    "hx1 = torch.zeros(2, 20)\n",
    "# batch, hidden size\n",
    "hx2 = torch.zeros(2, 20)\n",
    "outputs = []\n",
    "# appends first input\n",
    "outputs += [input_v]\n",
    "# loop \"2 time steps\"\n",
    "for i in range(2):    \n",
    "    # input to hidden 1\n",
    "    hx1 = rnn1(input_v, hx1)   \n",
    "    # hidden 1 to hidden 2\n",
    "    hx2 = rnn2(hx1, hx2) \n",
    "    # hidden 2 to linear\n",
    "    output = linear(hx2)\n",
    "    # appends output\n",
    "    outputs += [output]\n",
    "    # set next input equals to the last output\n",
    "    input_v = output\n",
    "\n",
    "outputs  = torch.stack(outputs, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0838, -0.9325,  0.9319, -1.3625],\n",
       "         [-0.5753,  1.5154,  1.2355, -0.6069]],\n",
       "\n",
       "        [[ 0.1156,  0.2244,  0.1560, -0.0310],\n",
       "         [ 0.0797,  0.2490,  0.1425, -0.0276]],\n",
       "\n",
       "        [[ 0.1024,  0.2254,  0.1240, -0.0450],\n",
       "         [ 0.0726,  0.2500,  0.1123, -0.0432]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "\n",
    "# features, hidden size, layers (important 2 layers!)\n",
    "rnn12 = nn.GRU(4, 20, 2)\n",
    "# hidden size, output\n",
    "linear = nn.Linear(20,4)\n",
    "\n",
    "# 2 batches, 4 features\n",
    "input_v = torch.randn(1, 2, 4)\n",
    "# batch, hidden size\n",
    "hx = torch.zeros(2, 2, 20)\n",
    "\n",
    "outputs = []\n",
    "# appends first input\n",
    "outputs += [input_v]\n",
    "# loop \"2 time steps\"\n",
    "for i in range(2):    \n",
    "    output, hidden = rnn12(input_v, hx) \n",
    "    output = linear(output)\n",
    "    outputs += [output]\n",
    "    input_v = output\n",
    "    hx = hidden\n",
    "\n",
    "outputs  = torch.stack(outputs, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0838, -0.9325,  0.9319, -1.3625],\n",
       "          [-0.5753,  1.5154,  1.2355, -0.6069]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1156,  0.2244,  0.1560, -0.0310],\n",
       "          [ 0.0797,  0.2490,  0.1425, -0.0276]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1024,  0.2254,  0.1240, -0.0450],\n",
       "          [ 0.0726,  0.2500,  0.1123, -0.0432]]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
